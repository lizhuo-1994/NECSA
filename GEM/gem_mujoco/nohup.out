WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

No protocol specified
{'env_type': 'mujoco', 'env_id': 'Humanoid-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'humanoid_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 500001, 'max_steps': 1000, 'delay_step': 0, 'order': 1, 'grid_num': 2, 'decay': 0.5, 'state_dim': 10, 'state_min': -10, 'state_max': 10, 'mode': 'state', 'reduction': False}
Logging to ./log_gem/mujoco/gem+tbp/humanoid_gem+tbp_0
max_step:  1000
Box(-inf, inf, (376,), float64) Box(-0.4000000059604645, 0.4000000059604645, (17,), float32)
max_step:  1000
seed=0, logdir=./log_gem/mujoco/gem+tbp/humanoid_gem+tbp_0
/home/lizhuo/miniconda3/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/run/train.py:32: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-07-27 18:30:30.014662: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2022-07-27 18:30:30.036952: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3417600000 Hz
2022-07-27 18:30:30.037856: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56418afd1d90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-07-27 18:30:30.037888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:98: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/td3/policies.py:283: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/lizhuo/miniconda3/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:138: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:203: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:226: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From /home/lizhuo/miniconda3/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:251: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:261: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/lizhuo/NECSA/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:264: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

GEM Agent Here
TD3 Update Memory Many Agent here
here (?, 1)
model building finished
----------------------------------------
| eval mean 100 episod... | 99.3       |
| eval_abs_qs_difference  | 49.25514   |
| eval_discount_q         | 90.4       |
| eval_ep_rewmean         | 99.6       |
| eval_eplenmean          | 21.3       |
| eval_qs                 | -1.6129628 |
| eval_qs_difference      | -49.3      |
| eval_time_elapsed       | 0          |
| total timesteps         | 1          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 73.3       |
| env_time                | 0          |
| ep_rewmean              | 128        |
| episodes                | 4          |
| eplenmean               | 25.5       |
| fps                     | 146        |
| mean 100 episode reward | 128        |
| n_updates               | 0          |
| qs_abs_difference       | 79.4       |
| qs_difference           | -79.4      |
| qs_mean                 | 0.33626693 |
| time_elapsed            | 0          |
| total timesteps         | 102        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 44.6       |
| env_time                | 0          |
| ep_rewmean              | 123        |
| episodes                | 8          |
| eplenmean               | 24.2       |
| fps                     | 259        |
| mean 100 episode reward | 122        |
| n_updates               | 0          |
| qs_abs_difference       | 50.4       |
| qs_difference           | -50.4      |
| qs_mean                 | 0.19883564 |
| time_elapsed            | 0          |
| total timesteps         | 194        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 38.2       |
| env_time                | 0          |
| ep_rewmean              | 121        |
| episodes                | 12         |
| eplenmean               | 23.9       |
| fps                     | 354        |
| mean 100 episode reward | 121        |
| n_updates               | 0          |
| qs_abs_difference       | 43.8       |
| qs_difference           | -43.8      |
| qs_mean                 | 0.25036752 |
| time_elapsed            | 0          |
| total timesteps         | 287        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 33.8       |
| env_time                | 0          |
| ep_rewmean              | 123        |
| episodes                | 16         |
| eplenmean               | 24.2       |
| fps                     | 436        |
| mean 100 episode reward | 122        |
| n_updates               | 0          |
| qs_abs_difference       | 42.5       |
| qs_difference           | -42.5      |
| qs_mean                 | 0.19432712 |
| time_elapsed            | 0          |
| total timesteps         | 387        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 83.8       |
| env_time                | 0          |
| ep_rewmean              | 126        |
| episodes                | 20         |
| eplenmean               | 24.9       |
| fps                     | 513        |
| mean 100 episode reward | 126        |
| n_updates               | 0          |
| qs_abs_difference       | 93.4       |
| qs_difference           | -93.4      |
| qs_mean                 | 0.23296095 |
| time_elapsed            | 0          |
| total timesteps         | 499        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 87.1       |
| env_time                | 0          |
| ep_rewmean              | 130        |
| episodes                | 24         |
| eplenmean               | 25.6       |
| fps                     | 558        |
| mean 100 episode reward | 130        |
| n_updates               | 0          |
| qs_abs_difference       | 102        |
| qs_difference           | -102       |
| qs_mean                 | 0.29840478 |
| time_elapsed            | 1          |
| total timesteps         | 614        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 46.1       |
| env_time                | 0          |
| ep_rewmean              | 125        |
| episodes                | 28         |
| eplenmean               | 24.6       |
| fps                     | 602        |
| mean 100 episode reward | 125        |
| n_updates               | 0          |
| qs_abs_difference       | 44.5       |
| qs_difference           | -44.5      |
| qs_mean                 | 0.18615015 |
| time_elapsed            | 1          |
| total timesteps         | 689        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 64.1      |
| env_time                | 0         |
| ep_rewmean              | 125       |
| episodes                | 32        |
| eplenmean               | 24.7      |
| fps                     | 634       |
| mean 100 episode reward | 125       |
| n_updates               | 0         |
| qs_abs_difference       | 73.2      |
| qs_difference           | -73.2     |
| qs_mean                 | 0.2594227 |
| time_elapsed            | 1         |
| total timesteps         | 790       |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 39        |
| env_time                | 0         |
| ep_rewmean              | 123       |
| episodes                | 36        |
| eplenmean               | 24.3      |
| fps                     | 649       |
| mean 100 episode reward | 123       |
| n_updates               | 0         |
| qs_abs_difference       | 41.7      |
| qs_difference           | -41.7     |
| qs_mean                 | 0.2653201 |
| time_elapsed            | 1         |
| total timesteps         | 875       |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 57.9       |
| env_time                | 0          |
| ep_rewmean              | 123        |
| episodes                | 40         |
| eplenmean               | 24.4       |
| fps                     | 632        |
| mean 100 episode reward | 123        |
| n_updates               | 0          |
| qs_abs_difference       | 66.1       |
| qs_difference           | -66.1      |
| qs_mean                 | 0.17004125 |
| time_elapsed            | 1          |
| total timesteps         | 975        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 55.8       |
| env_time                | 0          |
| ep_rewmean              | 121        |
| episodes                | 44         |
| eplenmean               | 24         |
| fps                     | 644        |
| mean 100 episode reward | 121        |
| n_updates               | 0          |
| qs_abs_difference       | 54.6       |
| qs_difference           | -54.6      |
| qs_mean                 | 0.29437986 |
| time_elapsed            | 1          |
| total timesteps         | 1055       |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 45.4       |
| env_time                | 0          |
| ep_rewmean              | 120        |
| episodes                | 48         |
| eplenmean               | 23.8       |
| fps                     | 649        |
| mean 100 episode reward | 120        |
| n_updates               | 0          |
| qs_abs_difference       | 49.5       |
| qs_difference           | -49.5      |
| qs_mean                 | 0.18369453 |
| time_elapsed            | 1          |
| total timesteps         | 1144       |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 41.7      |
| env_time                | 0         |
| ep_rewmean              | 120       |
| episodes                | 52        |
| eplenmean               | 23.8      |
| fps                     | 657       |
| mean 100 episode reward | 120       |
| n_updates               | 0         |
| qs_abs_difference       | 47.7      |
| qs_difference           | -47.7     |
| qs_mean                 | 0.1023228 |
| time_elapsed            | 1         |
| total timesteps         | 1236      |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 48.6      |
| env_time                | 0         |
| ep_rewmean              | 119       |
| episodes                | 56        |
| eplenmean               | 23.6      |
| fps                     | 627       |
| mean 100 episode reward | 119       |
| n_updates               | 0         |
| qs_abs_difference       | 51.9      |
| qs_difference           | -51.9     |
| qs_mean                 | 0.3859671 |
| time_elapsed            | 2         |
| total timesteps         | 1324      |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 38.2      |
| env_time                | 0         |
| ep_rewmean              | 119       |
| episodes                | 60        |
| eplenmean               | 23.5      |
| fps                     | 615       |
| mean 100 episode reward | 119       |
| n_updates               | 0         |
| qs_abs_difference       | 41.6      |
| qs_difference           | -41.6     |
| qs_mean                 | 0.2984515 |
| time_elapsed            | 2         |
| total timesteps         | 1411      |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 45.2       |
| env_time                | 0          |
| ep_rewmean              | 117        |
| episodes                | 64         |
| eplenmean               | 23.2       |
| fps                     | 635        |
| mean 100 episode reward | 117        |
| n_updates               | 0          |
| qs_abs_difference       | 44.4       |
| qs_difference           | -44.4      |
| qs_mean                 | 0.29567242 |
| time_elapsed            | 2          |
| total timesteps         | 1488       |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 45.3      |
| env_time                | 0         |
| ep_rewmean              | 117       |
| episodes                | 68        |
| eplenmean               | 23.1      |
| fps                     | 637       |
| mean 100 episode reward | 117       |
| n_updates               | 0         |
| qs_abs_difference       | 46.8      |
| qs_difference           | -46.8     |
| qs_mean                 | 0.3880354 |
| time_elapsed            | 2         |
| total timesteps         | 1571      |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 38         |
| env_time                | 0          |
| ep_rewmean              | 117        |
| episodes                | 72         |
| eplenmean               | 23.1       |
| fps                     | 610        |
| mean 100 episode reward | 117        |
| n_updates               | 0          |
| qs_abs_difference       | 44         |
| qs_difference           | -44        |
| qs_mean                 | 0.37773526 |
| time_elapsed            | 2          |
| total timesteps         | 1665       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 34.1       |
| env_time                | 1          |
| ep_rewmean              | 117        |
| episodes                | 76         |
| eplenmean               | 23.3       |
| fps                     | 600        |
| mean 100 episode reward | 118        |
| n_updates               | 0          |
| qs_abs_difference       | 44.5       |
| qs_difference           | -44.5      |
| qs_mean                 | 0.24751091 |
| time_elapsed            | 2          |
| total timesteps         | 1770       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 93.8      |
| env_time                | 1         |
| ep_rewmean              | 119       |
| episodes                | 80        |
| eplenmean               | 23.6      |
| fps                     | 571       |
| mean 100 episode reward | 119       |
| n_updates               | 0         |
| qs_abs_difference       | 106       |
| qs_difference           | -106      |
| qs_mean                 | 0.3000269 |
| time_elapsed            | 3         |
| total timesteps         | 1890      |
| train_time              | 0         |
| update_time             | 1         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 62.1       |
| env_time                | 1          |
| ep_rewmean              | 119        |
| episodes                | 84         |
| eplenmean               | 23.7       |
| fps                     | 551        |
| mean 100 episode reward | 120        |
| n_updates               | 0          |
| qs_abs_difference       | 69.3       |
| qs_difference           | -69.3      |
| qs_mean                 | 0.30694303 |
| time_elapsed            | 3          |
| total timesteps         | 1992       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 45.9       |
| env_time                | 1          |
| ep_rewmean              | 119        |
| episodes                | 88         |
| eplenmean               | 23.5       |
| fps                     | 503        |
| mean 100 episode reward | 118        |
| n_updates               | 0          |
| qs_abs_difference       | 45.8       |
| qs_difference           | -45.8      |
| qs_mean                 | 0.07211958 |
| time_elapsed            | 4          |
| total timesteps         | 2072       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 43.5       |
| env_time                | 1          |
| ep_rewmean              | 119        |
| episodes                | 92         |
| eplenmean               | 23.7       |
| fps                     | 505        |
| mean 100 episode reward | 119        |
| n_updates               | 0          |
| qs_abs_difference       | 56.3       |
| qs_difference           | -56.3      |
| qs_mean                 | 0.39437675 |
| time_elapsed            | 4          |
| total timesteps         | 2179       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 51.8       |
| env_time                | 1          |
| ep_rewmean              | 119        |
| episodes                | 96         |
| eplenmean               | 23.7       |
| fps                     | 510        |
| mean 100 episode reward | 119        |
| n_updates               | 0          |
| qs_abs_difference       | 56.4       |
| qs_difference           | -56.4      |
| qs_mean                 | 0.32947755 |
| time_elapsed            | 4          |
| total timesteps         | 2271       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 52.8      |
| env_time                | 1         |
| ep_rewmean              | 119       |
| episodes                | 100       |
| eplenmean               | 23.7      |
| fps                     | 496       |
| mean 100 episode reward | 119       |
| n_updates               | 0         |
| qs_abs_difference       | 59        |
| qs_difference           | -59       |
| qs_mean                 | 0.1888005 |
| time_elapsed            | 4         |
| total timesteps         | 2366      |
| train_time              | 0         |
| update_time             | 2         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 33.5       |
| env_time                | 1          |
| ep_rewmean              | 119        |
| episodes                | 104        |
| eplenmean               | 23.7       |
| fps                     | 468        |
| mean 100 episode reward | 119        |
| n_updates               | 0          |
| qs_abs_difference       | 43.8       |
| qs_difference           | -43.8      |
| qs_mean                 | 0.22769172 |
| time_elapsed            | 5          |
| total timesteps         | 2472       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 36.3       |
| env_time                | 1          |
| ep_rewmean              | 119        |
| episodes                | 108        |
| eplenmean               | 23.7       |
| fps                     | 454        |
| mean 100 episode reward | 119        |
| n_updates               | 0          |
| qs_abs_difference       | 41.5       |
| qs_difference           | -41.5      |
| qs_mean                 | 0.30863085 |
| time_elapsed            | 5          |
| total timesteps         | 2564       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 45.7       |
| env_time                | 1          |
| ep_rewmean              | 118        |
| episodes                | 112        |
| eplenmean               | 23.6       |
| fps                     | 427        |
| mean 100 episode reward | 118        |
| n_updates               | 0          |
| qs_abs_difference       | 47.6       |
| qs_difference           | -47.6      |
| qs_mean                 | 0.23397453 |
| time_elapsed            | 6          |
| total timesteps         | 2647       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 47.8       |
| env_time                | 1          |
| ep_rewmean              | 117        |
| episodes                | 116        |
| eplenmean               | 23.4       |
| fps                     | 408        |
| mean 100 episode reward | 117        |
| n_updates               | 0          |
| qs_abs_difference       | 47.1       |
| qs_difference           | -47.1      |
| qs_mean                 | 0.25940394 |
| time_elapsed            | 6          |
| total timesteps         | 2725       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 47.3       |
| env_time                | 1          |
| ep_rewmean              | 115        |
| episodes                | 120        |
| eplenmean               | 23         |
| fps                     | 416        |
| mean 100 episode reward | 115        |
| n_updates               | 0          |
| qs_abs_difference       | 44         |
| qs_difference           | -44        |
| qs_mean                 | 0.23578861 |
| time_elapsed            | 6          |
| total timesteps         | 2797       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 38.7       |
| env_time                | 1          |
| ep_rewmean              | 113        |
| episodes                | 124        |
| eplenmean               | 22.7       |
| fps                     | 396        |
| mean 100 episode reward | 113        |
| n_updates               | 0          |
| qs_abs_difference       | 41.8       |
| qs_difference           | -41.8      |
| qs_mean                 | 0.20795737 |
| time_elapsed            | 7          |
| total timesteps         | 2883       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 44.4       |
| env_time                | 1          |
| ep_rewmean              | 114        |
| episodes                | 128        |
| eplenmean               | 22.9       |
| fps                     | 389        |
| mean 100 episode reward | 114        |
| n_updates               | 0          |
| qs_abs_difference       | 50.9       |
| qs_difference           | -50.9      |
| qs_mean                 | 0.15954003 |
| time_elapsed            | 7          |
| total timesteps         | 2976       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 33.4       |
| env_time                | 1          |
| ep_rewmean              | 114        |
| episodes                | 132        |
| eplenmean               | 22.8       |
| fps                     | 380        |
| mean 100 episode reward | 114        |
| n_updates               | 0          |
| qs_abs_difference       | 39.7       |
| qs_difference           | -39.7      |
| qs_mean                 | 0.13140908 |
| time_elapsed            | 8          |
| total timesteps         | 3070       |
| train_time              | 0          |
| update_time             | 5          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 39.9       |
| env_time                | 2          |
| ep_rewmean              | 114        |
| episodes                | 136        |
| eplenmean               | 22.8       |
| fps                     | 366        |
| mean 100 episode reward | 114        |
| n_updates               | 0          |
| qs_abs_difference       | 41.9       |
| qs_difference           | -41.9      |
| qs_mean                 | 0.17300199 |
| time_elapsed            | 8          |
| total timesteps         | 3153       |
| train_time              | 0          |
| update_time             | 5          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 122        |
| env_time                | 2          |
| ep_rewmean              | 115        |
| episodes                | 140        |
| eplenmean               | 23         |
| fps                     | 358        |
| mean 100 episode reward | 115        |
| n_updates               | 0          |
| qs_abs_difference       | 131        |
| qs_difference           | -131       |
| qs_mean                 | 0.36827394 |
| time_elapsed            | 9          |
| total timesteps         | 3275       |
| train_time              | 0          |
| update_time             | 6          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 44.8       |
| env_time                | 2          |
| ep_rewmean              | 116        |
| episodes                | 144        |
| eplenmean               | 23.2       |
| fps                     | 353        |
| mean 100 episode reward | 116        |
| n_updates               | 0          |
| qs_abs_difference       | 54.7       |
| qs_difference           | -54.7      |
| qs_mean                 | 0.13228521 |
| time_elapsed            | 9          |
| total timesteps         | 3377       |
| train_time              | 0          |
| update_time             | 6          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 53.3       |
| env_time                | 2          |
| ep_rewmean              | 117        |
| episodes                | 148        |
| eplenmean               | 23.4       |
| fps                     | 339        |
| mean 100 episode reward | 117        |
| n_updates               | 0          |
| qs_abs_difference       | 63.9       |
| qs_difference           | -63.9      |
| qs_mean                 | 0.30408427 |
| time_elapsed            | 10         |
| total timesteps         | 3481       |
| train_time              | 0          |
| update_time             | 6          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 49.5      |
| env_time                | 2         |
| ep_rewmean              | 117       |
| episodes                | 152       |
| eplenmean               | 23.4      |
| fps                     | 328       |
| mean 100 episode reward | 117       |
| n_updates               | 0         |
| qs_abs_difference       | 56.3      |
| qs_difference           | -56.3     |
| qs_mean                 | 0.2671028 |
| time_elapsed            | 10        |
| total timesteps         | 3575      |
| train_time              | 0         |
| update_time             | 7         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 41.7       |
| env_time                | 2          |
| ep_rewmean              | 118        |
| episodes                | 156        |
| eplenmean               | 23.5       |
| fps                     | 315        |
| mean 100 episode reward | 118        |
| n_updates               | 0          |
| qs_abs_difference       | 51.5       |
| qs_difference           | -51.5      |
| qs_mean                 | 0.32055038 |
| time_elapsed            | 11         |
| total timesteps         | 3675       |
| train_time              | 0          |
| update_time             | 8          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 35.8       |
| env_time                | 2          |
| ep_rewmean              | 118        |
| episodes                | 160        |
| eplenmean               | 23.6       |
| fps                     | 300        |
| mean 100 episode reward | 118        |
| n_updates               | 0          |
| qs_abs_difference       | 42.1       |
| qs_difference           | -42.1      |
| qs_mean                 | 0.43128997 |
| time_elapsed            | 12         |
| total timesteps         | 3769       |
| train_time              | 0          |
| update_time             | 8          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 39.4       |
| env_time                | 2          |
| ep_rewmean              | 119        |
| episodes                | 164        |
| eplenmean               | 23.8       |
| fps                     | 290        |
| mean 100 episode reward | 119        |
| n_updates               | 0          |
| qs_abs_difference       | 47.8       |
| qs_difference           | -47.8      |
| qs_mean                 | 0.18975684 |
| time_elapsed            | 13         |
| total timesteps         | 3867       |
| train_time              | 0          |
| update_time             | 9          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 46.2       |
| env_time                | 2          |
| ep_rewmean              | 119        |
| episodes                | 168        |
| eplenmean               | 23.7       |
| fps                     | 292        |
| mean 100 episode reward | 119        |
| n_updates               | 0          |
| qs_abs_difference       | 44.7       |
| qs_difference           | -44.7      |
| qs_mean                 | 0.12946147 |
| time_elapsed            | 13         |
| total timesteps         | 3942       |
| train_time              | 0          |
| update_time             | 9          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 48.4       |
| env_time                | 2          |
| ep_rewmean              | 118        |
| episodes                | 172        |
| eplenmean               | 23.6       |
| fps                     | 285        |
| mean 100 episode reward | 118        |
| n_updates               | 0          |
| qs_abs_difference       | 51.3       |
| qs_difference           | -51.3      |
| qs_mean                 | 0.18883377 |
| time_elapsed            | 14         |
| total timesteps         | 4027       |
| train_time              | 0          |
| update_time             | 10         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 40.9       |
| env_time                | 2          |
| ep_rewmean              | 118        |
| episodes                | 176        |
| eplenmean               | 23.6       |
| fps                     | 280        |
| mean 100 episode reward | 118        |
| n_updates               | 0          |
| qs_abs_difference       | 52.7       |
| qs_difference           | -52.7      |
| qs_mean                 | 0.16709867 |
| time_elapsed            | 14         |
| total timesteps         | 4133       |
| train_time              | 0          |
| update_time             | 10         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 46.3       |
| env_time                | 2          |
| ep_rewmean              | 117        |
| episodes                | 180        |
| eplenmean               | 23.4       |
| fps                     | 274        |
| mean 100 episode reward | 117        |
| n_updates               | 0          |
| qs_abs_difference       | 51.6       |
| qs_difference           | -51.6      |
| qs_mean                 | 0.24957871 |
| time_elapsed            | 15         |
| total timesteps         | 4228       |
| train_time              | 0          |
| update_time             | 11         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 62.3       |
| env_time                | 2          |
| ep_rewmean              | 118        |
| episodes                | 184        |
| eplenmean               | 23.5       |
| fps                     | 270        |
| mean 100 episode reward | 118        |
| n_updates               | 0          |
| qs_abs_difference       | 81.5       |
| qs_difference           | -81.5      |
| qs_mean                 | 0.25963023 |
| time_elapsed            | 16         |
| total timesteps         | 4346       |
| train_time              | 0          |
| update_time             | 11         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 84.8       |
| env_time                | 3          |
| ep_rewmean              | 120        |
| episodes                | 188        |
| eplenmean               | 23.9       |
| fps                     | 263        |
| mean 100 episode reward | 120        |
| n_updates               | 0          |
| qs_abs_difference       | 90.3       |
| qs_difference           | -90.3      |
| qs_mean                 | 0.24429554 |
| time_elapsed            | 16         |
| total timesteps         | 4457       |
| train_time              | 0          |
| update_time             | 12         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 37.7       |
| env_time                | 3          |
| ep_rewmean              | 119        |
| episodes                | 192        |
| eplenmean               | 23.8       |
| fps                     | 256        |
| mean 100 episode reward | 119        |
| n_updates               | 0          |
| qs_abs_difference       | 46.6       |
| qs_difference           | -46.6      |
| qs_mean                 | 0.23492685 |
| time_elapsed            | 17         |
| total timesteps         | 4558       |
| train_time              | 0          |
| update_time             | 13         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 38.3       |
| env_time                | 3          |
| ep_rewmean              | 120        |
| episodes                | 196        |
| eplenmean               | 23.9       |
| fps                     | 250        |
| mean 100 episode reward | 120        |
| n_updates               | 0          |
| qs_abs_difference       | 47.7       |
| qs_difference           | -47.7      |
| qs_mean                 | 0.36741295 |
| time_elapsed            | 18         |
| total timesteps         | 4659       |
| train_time              | 0          |
| update_time             | 14         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 31.3        |
| env_time                | 3           |
| ep_rewmean              | 121         |
| episodes                | 200         |
| eplenmean               | 24.1        |
| fps                     | 247         |
| mean 100 episode reward | 121         |
| n_updates               | 0           |
| qs_abs_difference       | 44.1        |
| qs_difference           | -44.1       |
| qs_mean                 | 0.112110764 |
| time_elapsed            | 19          |
| total timesteps         | 4772        |
| train_time              | 0           |
| update_time             | 14          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 62.6       |
| env_time                | 3          |
| ep_rewmean              | 120        |
| episodes                | 204        |
| eplenmean               | 24         |
| fps                     | 245        |
| mean 100 episode reward | 120        |
| n_updates               | 0          |
| qs_abs_difference       | 70         |
| qs_difference           | -70        |
| qs_mean                 | 0.13010696 |
| time_elapsed            | 19         |
| total timesteps         | 4872       |
| train_time              | 0          |
| update_time             | 15         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 31.7       |
| env_time                | 3          |
| ep_rewmean              | 121        |
| episodes                | 208        |
| eplenmean               | 24.1       |
| fps                     | 239        |
| mean 100 episode reward | 121        |
| n_updates               | 0          |
| qs_abs_difference       | 39.8       |
| qs_difference           | -39.8      |
| qs_mean                 | 0.08858385 |
| time_elapsed            | 20         |
| total timesteps         | 4971       |
| train_time              | 0          |
| update_time             | 15         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 43.9       |
| env_time                | 3          |
| ep_rewmean              | 121        |
| episodes                | 212        |
| eplenmean               | 24.1       |
| fps                     | 238        |
| mean 100 episode reward | 121        |
| n_updates               | 0          |
| qs_abs_difference       | 47.7       |
| qs_difference           | -47.7      |
| qs_mean                 | 0.11156911 |
| time_elapsed            | 21         |
| total timesteps         | 5058       |
| train_time              | 0          |
| update_time             | 16         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 35.6       |
| env_time                | 3          |
| ep_rewmean              | 122        |
| episodes                | 216        |
| eplenmean               | 24.3       |
| fps                     | 232        |
| mean 100 episode reward | 122        |
| n_updates               | 0          |
| qs_abs_difference       | 44.6       |
| qs_difference           | -44.6      |
| qs_mean                 | 0.24022497 |
| time_elapsed            | 22         |
| total timesteps         | 5159       |
| train_time              | 0          |
| update_time             | 17         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 70.3       |
| env_time                | 3          |
| ep_rewmean              | 123        |
| episodes                | 220        |
| eplenmean               | 24.5       |
| fps                     | 229        |
| mean 100 episode reward | 123        |
| n_updates               | 0          |
| qs_abs_difference       | 71.3       |
| qs_difference           | -71.3      |
| qs_mean                 | 0.27835587 |
| time_elapsed            | 22         |
| total timesteps         | 5247       |
| train_time              | 0          |
| update_time             | 17         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 44.7      |
| env_time                | 3         |
| ep_rewmean              | 124       |
| episodes                | 224       |
| eplenmean               | 24.7      |
| fps                     | 225       |
| mean 100 episode reward | 124       |
| n_updates               | 0         |
| qs_abs_difference       | 55.1      |
| qs_difference           | -55.1     |
| qs_mean                 | 0.3419702 |
| time_elapsed            | 23        |
| total timesteps         | 5352      |
| train_time              | 0         |
| update_time             | 18        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 46.3       |
| env_time                | 3          |
| ep_rewmean              | 124        |
| episodes                | 228        |
| eplenmean               | 24.7       |
| fps                     | 219        |
| mean 100 episode reward | 124        |
| n_updates               | 0          |
| qs_abs_difference       | 52.4       |
| qs_difference           | -52.4      |
| qs_mean                 | 0.18778543 |
| time_elapsed            | 24         |
| total timesteps         | 5448       |
| train_time              | 0          |
| update_time             | 19         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 57.3       |
| env_time                | 3          |
| ep_rewmean              | 124        |
| episodes                | 232        |
| eplenmean               | 24.7       |
| fps                     | 215        |
| mean 100 episode reward | 124        |
| n_updates               | 0          |
| qs_abs_difference       | 62.4       |
| qs_difference           | -62.4      |
| qs_mean                 | 0.21833836 |
| time_elapsed            | 25         |
| total timesteps         | 5541       |
| train_time              | 0          |
| update_time             | 20         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 46         |
| env_time                | 3          |
| ep_rewmean              | 124        |
| episodes                | 236        |
| eplenmean               | 24.6       |
| fps                     | 213        |
| mean 100 episode reward | 124        |
| n_updates               | 0          |
| qs_abs_difference       | 44.2       |
| qs_difference           | -44.2      |
| qs_mean                 | 0.27139354 |
| time_elapsed            | 26         |
| total timesteps         | 5616       |
| train_time              | 0          |
| update_time             | 21         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 35.8      |
| env_time                | 3         |
| ep_rewmean              | 122       |
| episodes                | 240       |
| eplenmean               | 24.3      |
| fps                     | 208       |
| mean 100 episode reward | 122       |
| n_updates               | 0         |
| qs_abs_difference       | 41.4      |
| qs_difference           | -41.4     |
| qs_mean                 | 0.3348179 |
| time_elapsed            | 27        |
| total timesteps         | 5709      |
| train_time              | 0         |
| update_time             | 22        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 50.6       |
| env_time                | 3          |
| ep_rewmean              | 122        |
| episodes                | 244        |
| eplenmean               | 24.2       |
| fps                     | 204        |
| mean 100 episode reward | 122        |
| n_updates               | 0          |
| qs_abs_difference       | 55.9       |
| qs_difference           | -55.9      |
| qs_mean                 | 0.32363254 |
| time_elapsed            | 28         |
| total timesteps         | 5800       |
| train_time              | 0          |
| update_time             | 22         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 53.5      |
| env_time                | 3         |
| ep_rewmean              | 121       |
| episodes                | 248       |
| eplenmean               | 24        |
| fps                     | 206       |
| mean 100 episode reward | 121       |
| n_updates               | 0         |
| qs_abs_difference       | 55.3      |
| qs_difference           | -55.3     |
| qs_mean                 | 0.3251971 |
| time_elapsed            | 28        |
| total timesteps         | 5885      |
| train_time              | 0         |
| update_time             | 22        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 37.1       |
| env_time                | 4          |
| ep_rewmean              | 121        |
| episodes                | 252        |
| eplenmean               | 24.1       |
| fps                     | 202        |
| mean 100 episode reward | 121        |
| n_updates               | 0          |
| qs_abs_difference       | 47.9       |
| qs_difference           | -47.9      |
| qs_mean                 | 0.20187095 |
| time_elapsed            | 29         |
| total timesteps         | 5989       |
| train_time              | 0          |
| update_time             | 24         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 34         |
| env_time                | 4          |
| ep_rewmean              | 122        |
| episodes                | 256        |
| eplenmean               | 24.2       |
| fps                     | 192        |
| mean 100 episode reward | 122        |
| n_updates               | 0          |
| qs_abs_difference       | 46.4       |
| qs_difference           | -46.4      |
| qs_mean                 | 0.31705174 |
| time_elapsed            | 31         |
| total timesteps         | 6100       |
| train_time              | 0          |
| update_time             | 26         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 50.4       |
| env_time                | 4          |
| ep_rewmean              | 122        |
| episodes                | 260        |
| eplenmean               | 24.4       |
| fps                     | 190        |
| mean 100 episode reward | 122        |
| n_updates               | 0          |
| qs_abs_difference       | 60.6       |
| qs_difference           | -60.6      |
| qs_mean                 | 0.14213987 |
| time_elapsed            | 32         |
| total timesteps         | 6210       |
| train_time              | 0          |
| update_time             | 26         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 39.1       |
| env_time                | 4          |
| ep_rewmean              | 122        |
| episodes                | 264        |
| eplenmean               | 24.4       |
| fps                     | 186        |
| mean 100 episode reward | 122        |
| n_updates               | 0          |
| qs_abs_difference       | 44.9       |
| qs_difference           | -44.9      |
| qs_mean                 | 0.16276471 |
| time_elapsed            | 33         |
| total timesteps         | 6302       |
| train_time              | 0          |
| update_time             | 27         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 63.5      |
| env_time                | 4         |
| ep_rewmean              | 123       |
| episodes                | 268       |
| eplenmean               | 24.5      |
| fps                     | 189       |
| mean 100 episode reward | 123       |
| n_updates               | 0         |
| qs_abs_difference       | 66.6      |
| qs_difference           | -66.6     |
| qs_mean                 | 0.2700774 |
| time_elapsed            | 33        |
| total timesteps         | 6395      |
| train_time              | 0         |
| update_time             | 27        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 79.6       |
| env_time                | 4          |
| ep_rewmean              | 124        |
| episodes                | 272        |
| eplenmean               | 24.8       |
| fps                     | 181        |
| mean 100 episode reward | 124        |
| n_updates               | 0          |
| qs_abs_difference       | 88.4       |
| qs_difference           | -88.4      |
| qs_mean                 | 0.19553214 |
| time_elapsed            | 35         |
| total timesteps         | 6506       |
| train_time              | 0          |
| update_time             | 29         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 78.1       |
| env_time                | 4          |
| ep_rewmean              | 123        |
| episodes                | 276        |
| eplenmean               | 24.6       |
| fps                     | 183        |
| mean 100 episode reward | 123        |
| n_updates               | 0          |
| qs_abs_difference       | 76.7       |
| qs_difference           | -76.7      |
| qs_mean                 | 0.25347507 |
| time_elapsed            | 35         |
| total timesteps         | 6596       |
| train_time              | 0          |
| update_time             | 29         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 44.1       |
| env_time                | 4          |
| ep_rewmean              | 122        |
| episodes                | 280        |
| eplenmean               | 24.5       |
| fps                     | 179        |
| mean 100 episode reward | 122        |
| n_updates               | 0          |
| qs_abs_difference       | 44         |
| qs_difference           | -44        |
| qs_mean                 | 0.23875703 |
| time_elapsed            | 37         |
| total timesteps         | 6675       |
| train_time              | 0          |
| update_time             | 30         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 49.6      |
| env_time                | 4         |
| ep_rewmean              | 121       |
| episodes                | 284       |
| eplenmean               | 24.2      |
| fps                     | 176       |
| mean 100 episode reward | 121       |
| n_updates               | 0         |
| qs_abs_difference       | 56.2      |
| qs_difference           | -56.2     |
| qs_mean                 | 0.3281014 |
| time_elapsed            | 38        |
| total timesteps         | 6771      |
| train_time              | 0         |
| update_time             | 32        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 65.9       |
| env_time                | 4          |
| ep_rewmean              | 121        |
| episodes                | 288        |
| eplenmean               | 24.2       |
| fps                     | 173        |
| mean 100 episode reward | 121        |
| n_updates               | 0          |
| qs_abs_difference       | 73.9       |
| qs_difference           | -73.9      |
| qs_mean                 | 0.41700277 |
| time_elapsed            | 39         |
| total timesteps         | 6877       |
| train_time              | 0          |
| update_time             | 33         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 59.6       |
| env_time                | 4          |
| ep_rewmean              | 121        |
| episodes                | 292        |
| eplenmean               | 24.3       |
| fps                     | 170        |
| mean 100 episode reward | 121        |
| n_updates               | 0          |
| qs_abs_difference       | 71.9       |
| qs_difference           | -71.9      |
| qs_mean                 | 0.27467766 |
| time_elapsed            | 40         |
| total timesteps         | 6984       |
| train_time              | 0          |
| update_time             | 34         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 43.6      |
| env_time                | 4         |
| ep_rewmean              | 121       |
| episodes                | 296       |
| eplenmean               | 24.1      |
| fps                     | 168       |
| mean 100 episode reward | 121       |
| n_updates               | 0         |
| qs_abs_difference       | 47.6      |
| qs_difference           | -47.6     |
| qs_mean                 | 0.2578348 |
| time_elapsed            | 41        |
| total timesteps         | 7072      |
| train_time              | 0         |
| update_time             | 35        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 46.3       |
| env_time                | 4          |
| ep_rewmean              | 119        |
| episodes                | 300        |
| eplenmean               | 23.8       |
| fps                     | 165        |
| mean 100 episode reward | 119        |
| n_updates               | 0          |
| qs_abs_difference       | 47.8       |
| qs_difference           | -47.8      |
| qs_mean                 | 0.15958822 |
| time_elapsed            | 43         |
| total timesteps         | 7154       |
| train_time              | 0          |
| update_time             | 36         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 68.4       |
| env_time                | 5          |
| ep_rewmean              | 119        |
| episodes                | 304        |
| eplenmean               | 23.8       |
| fps                     | 161        |
| mean 100 episode reward | 119        |
| n_updates               | 0          |
| qs_abs_difference       | 73.8       |
| qs_difference           | -73.8      |
| qs_mean                 | 0.18144067 |
| time_elapsed            | 44         |
| total timesteps         | 7252       |
| train_time              | 0          |
| update_time             | 38         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 67.8      |
| env_time                | 5         |
| ep_rewmean              | 119       |
| episodes                | 308       |
| eplenmean               | 23.9      |
| fps                     | 158       |
| mean 100 episode reward | 120       |
| n_updates               | 0         |
| qs_abs_difference       | 78.9      |
| qs_difference           | -78.9     |
| qs_mean                 | 0.2467185 |
| time_elapsed            | 46        |
| total timesteps         | 7358      |
| train_time              | 0         |
| update_time             | 39        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 31.9       |
| env_time                | 5          |
| ep_rewmean              | 120        |
| episodes                | 312        |
| eplenmean               | 24.1       |
| fps                     | 157        |
| mean 100 episode reward | 120        |
| n_updates               | 0          |
| qs_abs_difference       | 41.8       |
| qs_difference           | -41.8      |
| qs_mean                 | 0.21972436 |
| time_elapsed            | 47         |
| total timesteps         | 7463       |
| train_time              | 0          |
| update_time             | 40         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 57.1      |
| env_time                | 5         |
| ep_rewmean              | 119       |
| episodes                | 316       |
| eplenmean               | 23.8      |
| fps                     | 154       |
| mean 100 episode reward | 119       |
| n_updates               | 0         |
| qs_abs_difference       | 54.9      |
| qs_difference           | -54.9     |
| qs_mean                 | 0.2505387 |
| time_elapsed            | 48        |
| total timesteps         | 7541      |
| train_time              | 0         |
| update_time             | 41        |
---------------------------------------
--------------------------------------
| act_time                | 0        |
| current_lr              | 0.0003   |
| discount_q              | 47.6     |
| env_time                | 5        |
| ep_rewmean              | 120      |
| episodes                | 320      |
| eplenmean               | 23.9     |
| fps                     | 151      |
| mean 100 episode reward | 120      |
| n_updates               | 0        |
| qs_abs_difference       | 55.6     |
| qs_difference           | -55.6    |
| qs_mean                 | 0.281993 |
| time_elapsed            | 50       |
| total timesteps         | 7638     |
| train_time              | 0        |
| update_time             | 43       |
--------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 63.5       |
| env_time                | 5          |
| ep_rewmean              | 120        |
| episodes                | 324        |
| eplenmean               | 23.9       |
| fps                     | 149        |
| mean 100 episode reward | 120        |
| n_updates               | 0          |
| qs_abs_difference       | 75.6       |
| qs_difference           | -75.6      |
| qs_mean                 | 0.36517677 |
| time_elapsed            | 51         |
| total timesteps         | 7746       |
| train_time              | 0          |
| update_time             | 44         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 39.3       |
| env_time                | 5          |
| ep_rewmean              | 121        |
| episodes                | 328        |
| eplenmean               | 24.1       |
| fps                     | 147        |
| mean 100 episode reward | 121        |
| n_updates               | 0          |
| qs_abs_difference       | 53.1       |
| qs_difference           | -53.1      |
| qs_mean                 | 0.34508005 |
| time_elapsed            | 53         |
| total timesteps         | 7859       |
| train_time              | 0          |
| update_time             | 45         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 42.4       |
| env_time                | 5          |
| ep_rewmean              | 121        |
| episodes                | 332        |
| eplenmean               | 24.1       |
| fps                     | 145        |
| mean 100 episode reward | 121        |
| n_updates               | 0          |
| qs_abs_difference       | 49.5       |
| qs_difference           | -49.5      |
| qs_mean                 | 0.24392088 |
| time_elapsed            | 54         |
| total timesteps         | 7955       |
| train_time              | 0          |
| update_time             | 46         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 72.5       |
| env_time                | 5          |
| ep_rewmean              | 122        |
| episodes                | 336        |
| eplenmean               | 24.4       |
| fps                     | 143        |
| mean 100 episode reward | 122        |
| n_updates               | 0          |
| qs_abs_difference       | 75.7       |
| qs_difference           | -75.7      |
| qs_mean                 | 0.15656842 |
| time_elapsed            | 55         |
| total timesteps         | 8051       |
| train_time              | 0          |
| update_time             | 48         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 51.6       |
| env_time                | 5          |
| ep_rewmean              | 123        |
| episodes                | 340        |
| eplenmean               | 24.5       |
| fps                     | 141        |
| mean 100 episode reward | 122        |
| n_updates               | 0          |
| qs_abs_difference       | 62         |
| qs_difference           | -62        |
| qs_mean                 | 0.41483065 |
| time_elapsed            | 57         |
| total timesteps         | 8158       |
| train_time              | 0          |
| update_time             | 49         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 54.5       |
| env_time                | 5          |
| ep_rewmean              | 124        |
| episodes                | 344        |
| eplenmean               | 24.7       |
| fps                     | 139        |
| mean 100 episode reward | 124        |
| n_updates               | 0          |
| qs_abs_difference       | 70.2       |
| qs_difference           | -70.2      |
| qs_mean                 | 0.28352872 |
| time_elapsed            | 59         |
| total timesteps         | 8270       |
| train_time              | 0          |
| update_time             | 51         |
----------------------------------------
